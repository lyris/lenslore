import { AutoProcessor, AutoModelForVision2Seq, env, RawImage } from '@huggingface/transformers';
import { config } from './config.js';

// Configure transformers.js
env.allowLocalModels = config.models.vision.useLocal;
env.allowRemoteModels = true;
env.backends.onnx.wasm.numThreads = 1;

// å¯ç”¨æµè§ˆå™¨ç¼“å­˜ä¼˜å…ˆç­–ç•¥ï¼ˆä¼˜å…ˆä½¿ç”¨ Cache API å’Œ Service Workerï¼‰
env.useBrowserCache = true;
env.useFSCache = true;

// é…ç½®é•œåƒæœåŠ¡å™¨ï¼ˆå¿…é¡»åœ¨å…¨å±€ env è®¾ç½®ï¼Œä¸èƒ½åœ¨ from_pretrained çš„ options é‡Œè®¾ç½®ï¼‰
if (config.mirror.enabled && config.mirror.url) {
    env.remoteHost = config.mirror.url;
    // HuggingFace çš„æ ‡å‡†è·¯å¾„æ¨¡æ¿æ˜¯ {model}/resolve/{revision}/
    // æˆ‘ä»¬çš„é•œåƒä¹Ÿéµå¾ªè¿™ä¸ªæ ¼å¼
    env.remotePathTemplate = '{model}/resolve/{revision}/';
    console.warn(`[ImageAnalyzer] âœ… Global mirror configured: ${config.mirror.url}`);
} else {
    console.warn(`[ImageAnalyzer] âš ï¸ Using default HuggingFace host (mirror not enabled)`);
}

// å·²ç§»é™¤åˆ†å—ä¸‹è½½åŠŸèƒ½ï¼ˆä¸ç¨³å®šï¼Œå·²åˆ é™¤ï¼‰



export class ImageAnalyzer {
    constructor() {
        this.model = null;
        this.processor = null;
        this.modelId = config.models.vision.useLocal
            ? config.models.vision.localPath
            : config.models.vision.id;
    }

    async init(progressCallback) {
        // æ ¹æ®ç”¨æˆ·åå¥½å†³å®šåŠ è½½ç­–ç•¥
        const devicePref = config.models.vision.devicePreference;
        const hasWebGPU = 'gpu' in navigator;

        // æ ¹æ®åå¥½å’Œæµè§ˆå™¨èƒ½åŠ›ç¡®å®šåŠ è½½å°è¯•åˆ—è¡¨
        let loadAttempts = [];

        if (devicePref === 'webgpu') {
            // å¼ºåˆ¶ WebGPU
            if (!hasWebGPU) {
                throw new Error('WebGPU not supported in this browser. Please switch to Auto or WASM mode.');
            }
            loadAttempts = [{ dtype: 'fp32', device: 'webgpu', vramNeeded: '~1.6GB VRAM' }];
        } else if (devicePref === 'wasm') {
            // å¼ºåˆ¶ WASM
            loadAttempts = [{ dtype: 'fp32', device: 'wasm', vramNeeded: 'CPU mode (no GPU)' }];
        } else {
            // è‡ªåŠ¨æ¨¡å¼ï¼šä¼˜å…ˆ WebGPUï¼Œå¤±è´¥åˆ™ WASM
            if (hasWebGPU) {
                loadAttempts = [
                    { dtype: 'fp32', device: 'webgpu', vramNeeded: '~1.6GB VRAM' },
                    { dtype: 'fp32', device: 'wasm', vramNeeded: 'CPU mode (no GPU)' }
                ];
            } else {
                console.warn('[ImageAnalyzer] No WebGPU support, using WASM directly');
                if (progressCallback) {
                    progressCallback({
                        progress: 'Preparing',
                        stage: 'fallback',
                        dtype: 'fp32',
                        device: 'wasm',
                        attemptInfo: 'No WebGPU, using CPU mode',
                        currentAttempt: 1,
                        totalAttempts: 1
                    });
                }
                return this.loadWithConfig('fp32', 'wasm', progressCallback, 1, 1);
            }
        }

        // ä¾æ¬¡å°è¯•æ¯ä¸ªé…ç½®
        for (let i = 0; i < loadAttempts.length; i++) {
            const { dtype, device, vramNeeded } = loadAttempts[i];

            try {
                console.log(`[ImageAnalyzer] ğŸ”„ Attempt ${i + 1}/${loadAttempts.length}: ${dtype.toUpperCase()}/${device.toUpperCase()} (${vramNeeded})`);

                // é€šçŸ¥ç”¨æˆ·å½“å‰å°è¯•
                if (progressCallback) {
                    progressCallback({
                        progress: 'Starting',
                        stage: 'attempt',
                        dtype: dtype,
                        device: device,
                        attemptInfo: `Trying ${dtype.toUpperCase()}/${device.toUpperCase()} (${vramNeeded})`,
                        currentAttempt: i + 1,
                        totalAttempts: loadAttempts.length
                    });
                }

                await this.loadWithConfig(dtype, device, progressCallback, i + 1, loadAttempts.length);

                console.log(`âœ… [ImageAnalyzer] Successfully loaded: ${dtype.toUpperCase()}/${device.toUpperCase()}`);
                return this.model;

            } catch (error) {
                const errorMsg = error.message || '';
                console.error(`âŒ [ImageAnalyzer] Failed ${dtype}/${device}:`, errorMsg);

                // æ£€æŸ¥æ˜¯å¦åº”è¯¥å°è¯•é™çº§åˆ°ä¸‹ä¸€ä¸ªé…ç½®
                const shouldFallback =
                    // æ˜¾å­˜/å†…å­˜ä¸è¶³é”™è¯¯
                    errorMsg.includes('allocation') ||
                    errorMsg.includes('out of memory') ||
                    errorMsg.includes('OOM') ||
                    errorMsg.includes('CreateBuffer') ||
                    errorMsg.includes('Aborted') ||  // WASM/WebGPU å†…å­˜åˆ†é…å¤±è´¥
                    errorMsg.includes('memory') ||
                    // WebGPU ä¸å¯ç”¨é”™è¯¯
                    errorMsg.includes('no available backend') ||
                    errorMsg.includes('Failed to get GPU adapter') ||
                    errorMsg.includes('enable-unsafe-webgpu') ||
                    errorMsg.includes('webgpu');

                if (shouldFallback && i < loadAttempts.length - 1) {
                    const nextAttempt = loadAttempts[i + 1];

                    // åˆ¤æ–­å¤±è´¥åŸå› 
                    const isWebGPUUnavailable = errorMsg.includes('backend') ||
                                               errorMsg.includes('GPU adapter') ||
                                               errorMsg.includes('webgpu');

                    const reason = isWebGPUUnavailable ?
                        'WebGPU unavailable' :
                        'GPU memory insufficient';

                    console.warn(`âš ï¸ [ImageAnalyzer] ${reason} for ${dtype}/${device}, switching to CPU mode...`);

                    // é€šçŸ¥ç”¨æˆ·ï¼šåˆ‡æ¢åˆ° CPU æ¨¡å¼
                    if (progressCallback) {
                        progressCallback({
                            progress: 'Downgrading',
                            stage: 'fallback',
                            dtype: dtype,
                            device: device,
                            attemptInfo: `${reason}, switching to CPU mode (${nextAttempt.dtype.toUpperCase()}/${nextAttempt.device.toUpperCase()})...`,
                            currentAttempt: i + 1,
                            totalAttempts: loadAttempts.length,
                            isDowngrade: true
                        });
                    }

                    // ç»§ç»­ä¸‹ä¸€ä¸ªé…ç½®
                    continue;
                }

                if (i === loadAttempts.length - 1) {
                    // æ‰€æœ‰é…ç½®éƒ½å¤±è´¥äº†
                    throw new Error(`âŒ Failed to load vision model with all configurations. Please try refreshing the page. Last error: ${errorMsg}`);
                }

                // ç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªé…ç½®ï¼ˆå³ä½¿ä¸æ˜¯å·²çŸ¥çš„å¯é™çº§é”™è¯¯ï¼‰
                if (i < loadAttempts.length - 1) {
                    console.warn(`âš ï¸ [ImageAnalyzer] Unknown error for ${dtype}/${device}, trying next configuration...`);
                    continue;
                }

                // æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼ŒæŠ›å‡ºé”™è¯¯
                throw error;
            }
        }
    }

    /**
     * ä½¿ç”¨æŒ‡å®šé…ç½®åŠ è½½æ¨¡å‹
     */
    async loadWithConfig(dtype, device, progressCallback, currentAttempt, totalAttempts) {
        // å­˜å‚¨é…ç½®
        this.currentConfig = { dtype, device };

        // åŠ¨æ€æ„å»ºæ¨¡å‹åŠ è½½é€‰é¡¹
        const modelOptions = {
            progress_callback: (progress) => {
                if (progressCallback) {
                    const percentage = progress.progress ?
                        Math.round(progress.progress) + '%' :
                        progress.status || '';

                    // æå–æ–‡ä»¶åå’Œå¤§å°ä¿¡æ¯
                    const fileName = progress.file || 'unknown';
                    const loaded = progress.loaded ? (progress.loaded / 1024 / 1024).toFixed(1) : 0;
                    const total = progress.total ? (progress.total / 1024 / 1024).toFixed(1) : 0;
                    const sizeInfo = total > 0 ? ` (${loaded}/${total}MB)` : '';

                    progressCallback({
                        progress: percentage,
                        stage: 'processor',
                        dtype: dtype,
                        device: device,
                        currentAttempt: currentAttempt,
                        totalAttempts: totalAttempts,
                        fileName: fileName,
                        sizeInfo: sizeInfo
                    });
                }
            }
        };

        // Load processor (é•œåƒå·²åœ¨å…¨å±€ env é…ç½®ï¼Œè¿™é‡Œä¸éœ€è¦å•ç‹¬è®¾ç½®)
        this.processor = await AutoProcessor.from_pretrained(this.modelId, modelOptions);

        // ä¸ºæ¨¡å‹åŠ è½½å‡†å¤‡é€‰é¡¹ï¼Œå¹¶å¤ç”¨/æ·»åŠ é•œåƒé…ç½®
        const modelLoadOptions = {
            dtype: dtype,
            device: device,
            progress_callback: (progress) => {
                if (progressCallback) {
                    const percentage = progress.progress ?
                        Math.round(progress.progress) + '%' :
                        progress.status || '';

                    // æå–æ–‡ä»¶åå’Œå¤§å°ä¿¡æ¯
                    const fileName = progress.file || 'unknown';
                    const loaded = progress.loaded ? (progress.loaded / 1024 / 1024).toFixed(1) : 0;
                    const total = progress.total ? (progress.total / 1024 / 1024).toFixed(1) : 0;
                    const sizeInfo = total > 0 ? ` (${loaded}/${total}MB)` : '';

                    progressCallback({
                        progress: percentage,
                        stage: 'model',
                        dtype: dtype,
                        device: device,
                        currentAttempt: currentAttempt,
                        totalAttempts: totalAttempts,
                        fileName: fileName,
                        sizeInfo: sizeInfo
                    });
                }
            }
        };

        // Load model (é•œåƒå·²åœ¨å…¨å±€ env é…ç½®ï¼Œè¿™é‡Œä¸éœ€è¦å•ç‹¬è®¾ç½®)
        this.model = await AutoModelForVision2Seq.from_pretrained(this.modelId, modelLoadOptions);
    }


    async analyze(imageCanvas, prompt = 'What do you see?') {
        if (!this.model || !this.processor) {
            throw new Error('Model not initialized. Call init() first.');
        }

        try {
            // Convert canvas to RawImage
            const imageUrl = imageCanvas.toDataURL();
            const image = await RawImage.fromURL(imageUrl);

            // Prepare messages in the format expected by SmolVLM
            const messages = [
                {
                    role: 'user',
                    content: [
                        { type: 'image', image: imageUrl },
                        { type: 'text', text: prompt }
                    ]
                }
            ];

            // Apply chat template to format the prompt
            const text = this.processor.apply_chat_template(messages, {
                add_generation_prompt: true
            });

            // Process inputs (tokenize text and encode image)
            const inputs = await this.processor(text, [image]);

            // Generate response
            const output = await this.model.generate({
                ...inputs,
                max_new_tokens: 1500,  // å¢åŠ åˆ°500ä¸ªtoken,é¿å…æˆªæ–­
                do_sample: false,
                repetition_penalty: 1.1
            });

            // Decode the generated tokens
            const decoded = this.processor.batch_decode(output, {
                skip_special_tokens: true
            });

            let response = decoded[0] || 'No response generated';

            // æå– Assistant çš„å›å¤éƒ¨åˆ†
            // æ ¼å¼é€šå¸¸æ˜¯: "User:\n\nWhat do you see?\nAssistant: [å›å¤å†…å®¹]"
            const assistantMatch = response.match(/Assistant:\s*([\s\S]*)/);
            if (assistantMatch && assistantMatch[1]) {
                response = assistantMatch[1].trim();
            }

            return response;
        } catch (error) {
            console.error('Error analyzing image:', error);
            throw error;
        }
    }
}
